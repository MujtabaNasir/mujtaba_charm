{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_mnist_images(images, labels):\n",
    "    \"\"\"\n",
    "    Visualizes MNIST images with their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        images (list of torch.Tensor): List of MNIST images, where each image is a tensor.\n",
    "        labels (list of torch.Tensor): List of labels corresponding to the images.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(20, 20))\n",
    "    for i, (img, label) in enumerate(zip(images, labels)):\n",
    "        img = img.squeeze().numpy()\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "        font = ImageFont.truetype(font_paths[i], 20)\n",
    "        text_img = Image.new('L', (28, 28), color=0)\n",
    "\n",
    "        draw = ImageDraw.Draw(text_img)\n",
    "        text_bbox = draw.textbbox((0, 0), str(labels[i].item()), font=font)\n",
    "        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
    "        text_position = ((text_img.width - text_width) // 2, (text_img.height - text_height) // 4)\n",
    "        draw.text(text_position, str(labels[i].item()), font=font, fill=255)\n",
    "\n",
    "        text_images.append(text_img)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def visualize_text_images(text_images,font_paths):\n",
    "    \"\"\"\n",
    "    Visualizes text images with their corresponding font information.\n",
    "\n",
    "    Args:\n",
    "        text_images (list of PIL.Image.Image): List of text images to be visualized.\n",
    "        font_paths (list of str): List of font file paths corresponding to each text image.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(text_images), figsize=(20, 20))\n",
    "    for i, text_img in enumerate(text_images):\n",
    "        axes[i].imshow(text_img, cmap='gray')\n",
    "        axes[i].set_title(f'Font: {font_paths[i].split(\"/\")[-1]}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def find_overlap(mnist_img, text_img):\n",
    "    \"\"\"\n",
    "    Finds and visualizes the overlap between MNIST images and text images.\n",
    "\n",
    "    Args:\n",
    "        mnist_img (torch.Tensor): MNIST image tensor.\n",
    "        text_images (list of PIL.Image.Image): List of text images to compare with MNIST images.\n",
    "\n",
    "    Displays:\n",
    "        - A plot showing the overlap between MNIST images and text images. Each subplot represents\n",
    "          the overlap with one text image.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(text_images), figsize=(20, 20))\n",
    "    for i, text_img in enumerate(text_images):\n",
    "        mnist_img_binary = (images[i].squeeze().numpy() > 0).astype(int)\n",
    "\n",
    "        text_img_np = np.array(text_img)\n",
    "        text_img_binary = (text_img_np > 0).astype(int)\n",
    "        overlap = mnist_img_binary & text_img_binary\n",
    "\n",
    "        axes[i].imshow(overlap, cmap='gray')\n",
    "        axes[i].set_title(f'Overlap with {font_paths[i].split(\"/\")[-1]}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def center_image(image):\n",
    "    \"\"\"\n",
    "    Centers an image on a 28x28 black background and displays it.\n",
    "\n",
    "    If the input is not a PIL image, it is converted from a numpy array.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image.Image or numpy.ndarray): The image to be centered. Can be a PIL image or a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "    img_width, img_height = image.size\n",
    "\n",
    "    background = Image.new('L', (28,28), color=0)    \n",
    "    bg_width, bg_height = background.size\n",
    "    position = ((bg_width - img_width) // 2, (bg_height - img_height) // 2)\n",
    "        \n",
    "    background.paste(image, position)\n",
    "\n",
    "    plt.imshow(background, cmap='gray')\n",
    "    plt.title(\"Center Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def shift_image(image, x, y):\n",
    "    \"\"\"\n",
    "    Shifts an image by the specified x and y offsets and displays it.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image.Image or numpy.ndarray): The image to be shifted. Can be a PIL image or a numpy array.\n",
    "        x (int): The number of pixels to shift the image horizontally.\n",
    "        y (int): The number of pixels to shift the image vertically.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value.\n",
    "    \"\"\"\n",
    "\n",
    "    image = np.array(image)\n",
    "    shifted_image = np.roll(image, y, axis=0) \n",
    "    shifted_image = np.roll(shifted_image, x, axis=1) \n",
    "    \n",
    "    plt.imshow(shifted_image, cmap='gray')\n",
    "    plt.title(\"Shift Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def scale_image(image, scale_factor):\n",
    "    \"\"\"\n",
    "    Scales an image by the specified scale factor and displays it.\n",
    "\n",
    "    If the input is not a PIL image, it is converted from a numpy array.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image.Image or numpy.ndarray): The image to be scaled. Can be a PIL image or a numpy array.\n",
    "        scale_factor (float): The factor by which to scale the image. For example, 0.5 scales the image down by half.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "    \n",
    "    new_size = (int(image.width * scale_factor), int(image.height * scale_factor))\n",
    "    scaled_image = image.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    plt.imshow(scaled_image, cmap='gray')\n",
    "    plt.title(\"Scale Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def display_mnist_and_text_overlap(mnist_image, text_image):\n",
    "    \"\"\"\n",
    "    Displays the overlap between an MNIST image and a text image with different colors for different regions.\n",
    "\n",
    "    Args:\n",
    "        mnist_image (torch.Tensor): The MNIST image to compare, as a tensor.\n",
    "        text_image (PIL.Image.Image or numpy.ndarray): The text image to compare, as a PIL image or a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value.\n",
    "    \"\"\"\n",
    "    \n",
    "    mnist_binary = (mnist_image.squeeze().numpy() > 0).astype(int)\n",
    "    text_binary = (np.array(text_image) > 0).astype(int)\n",
    "\n",
    "    overlap_image = np.zeros((mnist_binary.shape[0], mnist_binary.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    YELLOW = [255, 255, 0]  # RGB for yellow\n",
    "    GREEN = [0, 255, 0]     # RGB for green\n",
    "    GRAY = [128, 128, 128]  # RGB for gray\n",
    "\n",
    "    overlap_image[mnist_binary == 1] = YELLOW\n",
    "\n",
    "    overlap_image[text_binary == 1] = GREEN\n",
    "\n",
    "    overlap_image[(mnist_binary == 1) & (text_binary == 1)] = GRAY\n",
    "    \n",
    "    plt.imshow(overlap_image)\n",
    "    plt.title(\"Mnist & Text Image with different colored intersection\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  font_paths = [\n",
    "      './fonts/OpenSans-Regular.ttf',\n",
    "      './fonts/Roboto-Regular.ttf',\n",
    "      './fonts/Ubuntu-Regular.ttf'\n",
    "  ]\n",
    "\n",
    "  text_images = []\n",
    "\n",
    "  transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "  mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "  dataloader = torch.utils.data.DataLoader(mnist_dataset, batch_size=3, shuffle=True)\n",
    "  images, labels = next(iter(dataloader))\n",
    "\n",
    "  visualize_mnist_images(images, labels)\n",
    "  visualize_text_images(text_images,font_paths)\n",
    "  find_overlap(images, text_images)\n",
    "  center_image(images[0].squeeze().numpy())\n",
    "  shift_image(images[0].squeeze().numpy(), 5, 0)\n",
    "  scale_image(images[0].squeeze().numpy(), 1.2)\n",
    "  display_mnist_and_text_overlap(images[1], text_images[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
